# Author: Qian Liu
# Email: liu.qian.pro@gmail.com

import torch, numpy as np
import torch.nn.functional as F
from sam2.build_sam import build_sam2
from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator
import argparse
from tqdm import tqdm
from PIL import Image
from pathlib import Path
import glob, json, os


def get_sam2_masks(image, device='cuda:0'):
    """
    Get SAM2 masks for a given image.
    :param image: Input image as a numpy array, (H, W, C).
    :param device: GPU device to use for computation.
    :return: List of masks generated by SAM2.
    """
    sam2_checkpoint = "checkpoints/sam2.1_hiera_large.pt"
    # sam2_checkpoint = "checkpoints/sam2.1_hiera_base_plus.pt"
    model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
    # model_cfg = "configs/sam2.1/sam2.1_hiera_b+.yaml"

    sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)

    # mask_generator = SAM2AutomaticMaskGenerator(sam2)
    mask_generator = SAM2AutomaticMaskGenerator(
        model=sam2,
        points_per_side=128,
        points_per_batch=128,
        pred_iou_thresh=0.7,
        stability_score_thresh=0.92,
        stability_score_offset=0.7,
        crop_n_layers=1,
        box_nms_thresh=0.7,
        crop_n_points_downscale_factor=2,
        min_mask_region_area=25.0,
        use_m2m=True,
    )

    masks = mask_generator.generate(image)
    masks = [mask['segmentation'] for mask in masks]  # Extract only the segmentation masks
    masks = torch.tensor(masks, dtype=torch.bool)  # Convert to tensor

    del sam2
    del mask_generator
    torch.cuda.empty_cache()

    return masks


def get_sam2_masks_from_path(args):
    """
    Get SAM2 masks for images in a specified directory.
    :param args: Arguments containing input path and GPU ID.
    :return: List of masks for each image.
    """
    device = torch.device(f"cuda:{args.gpu_id}" if torch.cuda.is_available() else "cpu")

    image_paths = sorted(glob.glob(f"{args.input_path}/*.jpg"))
    print(f"Found {len(image_paths)} images in {args.input_path}")
    # save the extracted masks
    save_path = args.save_path
    os.makedirs(save_path, exist_ok=True)

    for image_path in tqdm(image_paths, desc="Processing images"):
        image_path = Path(image_path)
        image = np.array(Image.open(image_path).convert("RGB"))
        masks = get_sam2_masks(image, device=device)

        save_file_path = os.path.join(save_path, f"{image_path.stem}.pt")
        torch.save(masks, save_file_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Extract SAM2 masks from images")
    parser.add_argument("--input_path", type=str, required=True, help="Path to input images directory")
    parser.add_argument("--save_path", type=str, default="", help="Path to save output masks")
    parser.add_argument("--gpu_id", type=int, default=0, help="GPU ID to use for computation")
    args = parser.parse_args()

    get_sam2_masks_from_path(args)
    print(f"Processing complete.")