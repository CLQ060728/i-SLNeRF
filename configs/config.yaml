data:
  data_root: [.../data/...] # absolute path to the dataset
  aabb_type: specified # different types of aabbs, choose from ["front", "specified"]
  aabb: [-120.0, -120.0, -20.0, 120.0, 120.0, 60.0] # [-80.0, -80.0, -5.0, 80.0, 80.0, 7.8] size: [0.1m, 0.1m, 0.2m] and size: [0.4m, 0.4m, 0.4m]
                                              # [-40.0, -40.0, -1.0, 40.0, 40.0, 5.4] for Waymo
                                              # size: [0.4m, 0.4m, 0.4m]
                                              # [-40.0, -40.0, -1.0, 40.0, 40.0, 5.4] for NuScenes
                                              # size: [0.1m, 0.1m, 0.1m] - [-100.0, -100.0, -10.0, 100.0, 100.0, 10.0]
                                              # for Waymo
                                              # size: [0.4m, 0.4m, 0.4m] - [-120.0, -120.0, -20.0, 120.0, 120.0, 60.0]
                                              # for Waymo and NuScenes, the pre-defined aabb for the scene
  ray_batch_size: 8192 # ray batch size for training, it's embedded in the dataset class for now
  pixel_source: # everything related to "pixels" --- from camera images
    load_size:  [640, 960] # [height, width], resize the raw image to this size [640, 960] [1280, 1920]
    num_cams: 5 # number of cameras to use, choose from [1, 3, 5] for waymo, [1, 3, 6] for nuscenes. 1: frontal, 3: frontal + frontal_left + frontal_right
    load_rgb: True  # whether to load rgb images
    load_sky_mask: True  # whether to load sky masks. We provide pre-extracted sky masks for waymo and nuscenes on google drive
    load_depth_map: True # whether to load depth maps. We provide pre-extracted depth maps for waymo and nuscenes
  lidar_source: # everything related to "lidar" --- from lidar points
    load_lidar: False 

nerf:
  unbounded: True # use unbounded contraction as in mipnerf360 / merf
  contract_method: inner_outer # choose contraction methods from ["inner_outer", "aabb_bounded"]
  inner_range: [80.0 ,80.0 ,20.0] # 0.4 - [80.0 ,80.0 ,20.0] - [240, 80]
                                 # 0.1 - [-50.0, -50.0, -10.0, 50.0, 50.0, 10.0] - [100, 50] 
                                 # inner range for the unbounded contraction
  contract_ratio: 0.8 # how much to contract the aabb, 0.8 means 80% of the aabb
  
  propnet: # proposal networks hyperparameters
    num_samples_per_prop: [128, 64] # how many samples to use for each propnet
  sampling: # sampling hyperparameters
    num_samples: 128 # final number of samples used for querying i-SLNeRF
  # sampling strategy, for aabb_bounded, we can use [128, 64], [200, 100], [240, 120] for propnet
  # 128, 200, 240 for i-SLNeRF; 
  
  model:
    neck:
      base_mlp_layer_width: 128
      geometry_feature_dim: 256 # 64 fine tuning point
      # ======= segmentations neck ======= #
      segmentation_feature_dim: 256 # 256 - when split_semantic_instance is True;
                                    # 128 - when split_semantic_instance is False;
    head:
      head_mlp_layer_width: 256 # 64 fine tuning point
      # ========== segmentations ======== #
      enable_segmentation_head: True # whether to use segmentation head
      split_semantic_instance: True # whether to use separate head for semantic and instance segmentation optimization
      semantic_hidden_dim: 256 # hidden dimension for semantic segmentation head
      instance_hidden_dim: 256 # hidden dimension for instance segmentation head
      semantic_embedding_dim: 256 # semantic embedding dimension
      instance_embedding_dim: 256 # instance embedding dimension
      # ======= appearance embedding ======= #
      enable_cam_embedding: False # whether to use camera embedding, for novel view synthesis
      enable_img_embedding: True # whether to use image embedding, for scene reconstruction
      appearance_embedding_dim: 16 # appearance embedding dimension for each camera or image
      
      enable_sky_head: True # whether to use sky head
      enable_dynamic_branch: True # whether to use dynamic branch
      enable_shadow_head: True # whether to use shadow head to predict shadow ratio
      enable_flow_branch: True # whether to use flow branch

render:
  render_low_res: False # whether to render low resolution images