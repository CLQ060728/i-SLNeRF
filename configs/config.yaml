data:
  data_root: /nas-data/qian_workspace/i-SLNeRF_on/data/Waymo/ # absolute path to the dataset
  ray_batch_size: 8192 # ray batch size for training, it's embedded in the dataset class for now
  pixel_source: # everything related to "pixels" --- from camera images
    load_size:  [640, 960] # [height, width], resize the raw image to this size [640, 960] [1280, 1920]
    num_cams: 5 # number of cameras to use, choose from [1, 3, 5] for waymo, [1, 3, 6] for nuscenes. 1: frontal, 3: frontal + frontal_left + frontal_right
    load_rgb: True  # whether to load rgb images
    load_sky_mask: True  # whether to load sky masks. We provide pre-extracted sky masks for waymo and nuscenes on google drive
    load_depth_map: True # whether to load depth maps. We provide pre-extracted depth maps for waymo and nuscenes
  lidar_source: # everything related to "lidar" --- from lidar points
    load_lidar: False 

nerf:
  model:
    head:
      enable_sky_head: True # whether to use sky head
      enable_dynamic_branch: True # whether to use dynamic branch
      enable_shadow_head: True # whether to use shadow head to predict shadow ratio
      enable_flow_branch: True # whether to use flow branch

render:
  render_low_res: False # whether to render low resolution images